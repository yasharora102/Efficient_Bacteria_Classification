{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_9dghDsTugR"
      },
      "source": [
        "# Code for the project:\n",
        "\n",
        "## BioVision-X: Efficient Bacterial Classification in Microscopy Imaging using CNN-Transformer Hybrid Models\n",
        "\n",
        "### Architecture: EfficientNet B0 + Transformer Blocks\n",
        "### Data: Original + Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcAeMJJzTugT"
      },
      "source": [
        "#### Loading libraries and Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W4kwcO4XLHp",
        "outputId": "f8f22a3c-01fe-4182-b140-202a8beaf207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting torch==2.5.1 (from xformers)\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->xformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1->xformers)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n",
            "Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers, torchmetrics, pytorch_lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lightning-utilities-0.11.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pytorch_lightning-2.4.0 torch-2.5.1 torchmetrics-1.6.0 triton-3.1.0 xformers-0.0.28.post3\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre torch\n",
        "!pip install xformers pytorch_lightning numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Y7BY91ZeAx",
        "outputId": "def79b49-fc23-4509-ccc6-99708e11b238"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-b9046d3babbd>:4: FutureWarning: xformers.components is deprecated and is not maintained anymore. It might be removed in a future version of xFormers \n",
            "  from xformers.components.attention import ScaledDotProduct\n",
            "WARNING:xformers:Either FairScale or torch distributed is not available, MixtureOfExperts will not be exposed. Please install them if you would like to use MoE\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import mobilenet_v2\n",
        "from xformers.components.attention import ScaledDotProduct\n",
        "from xformers.components.feedforward import MLP\n",
        "from einops import rearrange\n",
        "import numbers\n",
        "from xformers.components import build_attention, feedforward\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgTfKHtwa0zR",
        "outputId": "670a466d-70e7-4037-fc28-62b12923bafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-11-15 06:19:43--  https://raw.githubusercontent.com/gallardorafael/EfficientMobileDL_Bacterial/refs/heads/main/Notebooks/scripts/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4120 (4.0K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   4.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-15 06:19:43 (71.9 MB/s) - ‘utils.py’ saved [4120/4120]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/gallardorafael/EfficientMobileDL_Bacterial/refs/heads/main/Notebooks/scripts/utils.py\n",
        "!mkdir scripts\n",
        "!mv utils.py scripts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzELWiyTcJD9",
        "outputId": "b070b172-aaf0-4b40-f089-d84826cd61a5"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-model-summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhBCXO4smvDx",
        "outputId": "fe0e63b1-9617-4c82-a516-2feb72340b9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Correct_DIBAS\n"
          ]
        }
      ],
      "source": [
        "!mkdir Correct_DIBAS\n",
        "%cd /content/Correct_DIBAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOUmH2ghlsYa",
        "outputId": "04574813-33cf-4912-d5dc-eb92ab85623c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-11-15 06:19:49--  https://doctoral.matinf.uj.edu.pl/database/dibas/Acinetobacter.baumanii.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124685064 (119M) [application/zip]\n",
            "Saving to: ‘Acinetobacter.baumanii.zip’\n",
            "\n",
            "Acinetobacter.bauma 100%[===================>] 118.91M  10.1MB/s    in 13s     \n",
            "\n",
            "2024-11-15 06:20:04 (8.93 MB/s) - ‘Acinetobacter.baumanii.zip’ saved [124685064/124685064]\n",
            "\n",
            "--2024-11-15 06:20:04--  https://doctoral.matinf.uj.edu.pl/database/dibas/Actinomyces.israeli.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 155559855 (148M) [application/zip]\n",
            "Saving to: ‘Actinomyces.israeli.zip’\n",
            "\n",
            "Actinomyces.israeli 100%[===================>] 148.35M  10.2MB/s    in 16s     \n",
            "\n",
            "2024-11-15 06:20:21 (9.29 MB/s) - ‘Actinomyces.israeli.zip’ saved [155559855/155559855]\n",
            "\n",
            "--2024-11-15 06:20:21--  https://doctoral.matinf.uj.edu.pl/database/dibas/Bacteroides.fragilis.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138553396 (132M) [application/zip]\n",
            "Saving to: ‘Bacteroides.fragilis.zip’\n",
            "\n",
            "Bacteroides.fragili 100%[===================>] 132.13M  10.2MB/s    in 15s     \n",
            "\n",
            "2024-11-15 06:20:37 (8.85 MB/s) - ‘Bacteroides.fragilis.zip’ saved [138553396/138553396]\n",
            "\n",
            "--2024-11-15 06:20:37--  https://doctoral.matinf.uj.edu.pl/database/dibas/Bifidobacterium.spp.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154508113 (147M) [application/zip]\n",
            "Saving to: ‘Bifidobacterium.spp.zip’\n",
            "\n",
            "Bifidobacterium.spp 100%[===================>] 147.35M  10.2MB/s    in 16s     \n",
            "\n",
            "2024-11-15 06:20:54 (9.14 MB/s) - ‘Bifidobacterium.spp.zip’ saved [154508113/154508113]\n",
            "\n",
            "--2024-11-15 06:20:54--  https://doctoral.matinf.uj.edu.pl/database/dibas/Clostridium.perfringens.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 157835280 (151M) [application/zip]\n",
            "Saving to: ‘Clostridium.perfringens.zip’\n",
            "\n",
            "Clostridium.perfrin 100%[===================>] 150.52M  10.3MB/s    in 17s     \n",
            "\n",
            "2024-11-15 06:21:12 (9.04 MB/s) - ‘Clostridium.perfringens.zip’ saved [157835280/157835280]\n",
            "\n",
            "--2024-11-15 06:21:12--  https://doctoral.matinf.uj.edu.pl/database/dibas/Enterococcus.faecium.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113433587 (108M) [application/zip]\n",
            "Saving to: ‘Enterococcus.faecium.zip’\n",
            "\n",
            "Enterococcus.faeciu 100%[===================>] 108.18M  10.2MB/s    in 12s     \n",
            "\n",
            "2024-11-15 06:21:25 (9.01 MB/s) - ‘Enterococcus.faecium.zip’ saved [113433587/113433587]\n",
            "\n",
            "--2024-11-15 06:21:26--  https://doctoral.matinf.uj.edu.pl/database/dibas/Enterococcus.faecalis.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113547436 (108M) [application/zip]\n",
            "Saving to: ‘Enterococcus.faecalis.zip’\n",
            "\n",
            "Enterococcus.faecal 100%[===================>] 108.29M  10.1MB/s    in 12s     \n",
            "\n",
            "2024-11-15 06:21:39 (8.82 MB/s) - ‘Enterococcus.faecalis.zip’ saved [113547436/113547436]\n",
            "\n",
            "--2024-11-15 06:21:39--  https://doctoral.matinf.uj.edu.pl/database/dibas/Escherichia.coli.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110205523 (105M) [application/zip]\n",
            "Saving to: ‘Escherichia.coli.zip’\n",
            "\n",
            "Escherichia.coli.zi 100%[===================>] 105.10M  10.4MB/s    in 12s     \n",
            "\n",
            "2024-11-15 06:21:52 (9.10 MB/s) - ‘Escherichia.coli.zip’ saved [110205523/110205523]\n",
            "\n",
            "--2024-11-15 06:21:52--  https://doctoral.matinf.uj.edu.pl/database/dibas/Fusobacterium.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149053528 (142M) [application/zip]\n",
            "Saving to: ‘Fusobacterium.zip’\n",
            "\n",
            "Fusobacterium.zip   100%[===================>] 142.15M  10.2MB/s    in 16s     \n",
            "\n",
            "2024-11-15 06:22:08 (9.14 MB/s) - ‘Fusobacterium.zip’ saved [149053528/149053528]\n",
            "\n",
            "--2024-11-15 06:22:08--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.casei.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147460343 (141M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.casei.zip’\n",
            "\n",
            "Lactobacillus.casei 100%[===================>] 140.63M  10.5MB/s    in 15s     \n",
            "\n",
            "2024-11-15 06:22:25 (9.25 MB/s) - ‘Lactobacillus.casei.zip’ saved [147460343/147460343]\n",
            "\n",
            "--2024-11-15 06:22:25--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.crispatus.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124343668 (119M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.crispatus.zip’\n",
            "\n",
            "Lactobacillus.crisp 100%[===================>] 118.58M  10.1MB/s    in 13s     \n",
            "\n",
            "2024-11-15 06:22:40 (9.04 MB/s) - ‘Lactobacillus.crispatus.zip’ saved [124343668/124343668]\n",
            "\n",
            "--2024-11-15 06:22:40--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.delbrueckii.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118663464 (113M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.delbrueckii.zip’\n",
            "\n",
            "Lactobacillus.delbr 100%[===================>] 113.17M  7.39MB/s    in 14s     \n",
            "\n",
            "2024-11-15 06:22:55 (7.90 MB/s) - ‘Lactobacillus.delbrueckii.zip’ saved [118663464/118663464]\n",
            "\n",
            "--2024-11-15 06:22:55--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.gasseri.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114355706 (109M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.gasseri.zip’\n",
            "\n",
            "Lactobacillus.gasse 100%[===================>] 109.06M  10.2MB/s    in 12s     \n",
            "\n",
            "2024-11-15 06:23:09 (8.78 MB/s) - ‘Lactobacillus.gasseri.zip’ saved [114355706/114355706]\n",
            "\n",
            "--2024-11-15 06:23:09--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.jehnsenii.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117834331 (112M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.jehnsenii.zip’\n",
            "\n",
            "Lactobacillus.jehns 100%[===================>] 112.38M  10.4MB/s    in 13s     \n",
            "\n",
            "2024-11-15 06:23:23 (8.88 MB/s) - ‘Lactobacillus.jehnsenii.zip’ saved [117834331/117834331]\n",
            "\n",
            "--2024-11-15 06:23:23--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.johnsonii.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143809800 (137M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.johnsonii.zip’\n",
            "\n",
            "Lactobacillus.johns 100%[===================>] 137.15M  10.0MB/s    in 16s     \n",
            "\n",
            "2024-11-15 06:23:39 (8.61 MB/s) - ‘Lactobacillus.johnsonii.zip’ saved [143809800/143809800]\n",
            "\n",
            "--2024-11-15 06:23:39--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.paracasei.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138027801 (132M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.paracasei.zip’\n",
            "\n",
            "Lactobacillus.parac 100%[===================>] 131.63M  9.94MB/s    in 15s     \n",
            "\n",
            "2024-11-15 06:23:56 (8.81 MB/s) - ‘Lactobacillus.paracasei.zip’ saved [138027801/138027801]\n",
            "\n",
            "--2024-11-15 06:23:56--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.plantarum.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128095143 (122M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.plantarum.zip’\n",
            "\n",
            "Lactobacillus.plant 100%[===================>] 122.16M  10.3MB/s    in 14s     \n",
            "\n",
            "2024-11-15 06:24:10 (8.87 MB/s) - ‘Lactobacillus.plantarum.zip’ saved [128095143/128095143]\n",
            "\n",
            "--2024-11-15 06:24:10--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.reuteri.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 153858737 (147M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.reuteri.zip’\n",
            "\n",
            "Lactobacillus.reute 100%[===================>] 146.73M  10.2MB/s    in 18s     \n",
            "\n",
            "2024-11-15 06:24:29 (8.24 MB/s) - ‘Lactobacillus.reuteri.zip’ saved [153858737/153858737]\n",
            "\n",
            "--2024-11-15 06:24:29--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.rhamnosus.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109513663 (104M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.rhamnosus.zip’\n",
            "\n",
            "Lactobacillus.rhamn 100%[===================>] 104.44M  10.2MB/s    in 12s     \n",
            "\n",
            "2024-11-15 06:24:42 (8.71 MB/s) - ‘Lactobacillus.rhamnosus.zip’ saved [109513663/109513663]\n",
            "\n",
            "--2024-11-15 06:24:42--  https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.salivarius.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138876913 (132M) [application/zip]\n",
            "Saving to: ‘Lactobacillus.salivarius.zip’\n",
            "\n",
            "Lactobacillus.saliv 100%[===================>] 132.44M  10.2MB/s    in 16s     \n",
            "\n",
            "2024-11-15 06:24:59 (8.48 MB/s) - ‘Lactobacillus.salivarius.zip’ saved [138876913/138876913]\n",
            "\n",
            "--2024-11-15 06:24:59--  https://doctoral.matinf.uj.edu.pl/database/dibas/Listeria.monocytogenes.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166940087 (159M) [application/zip]\n",
            "Saving to: ‘Listeria.monocytogenes.zip’\n",
            "\n",
            "Listeria.monocytoge 100%[===================>] 159.21M  10.3MB/s    in 17s     \n",
            "\n",
            "2024-11-15 06:25:18 (9.17 MB/s) - ‘Listeria.monocytogenes.zip’ saved [166940087/166940087]\n",
            "\n",
            "--2024-11-15 06:25:18--  https://doctoral.matinf.uj.edu.pl/database/dibas/Micrococcus.spp.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133231634 (127M) [application/zip]\n",
            "Saving to: ‘Micrococcus.spp.zip’\n",
            "\n",
            "Micrococcus.spp.zip 100%[===================>] 127.06M  9.72MB/s    in 17s     \n",
            "\n",
            "2024-11-15 06:25:36 (7.41 MB/s) - ‘Micrococcus.spp.zip’ saved [133231634/133231634]\n",
            "\n",
            "--2024-11-15 06:25:36--  https://doctoral.matinf.uj.edu.pl/database/dibas/Neisseria.gonorrhoeae.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147695637 (141M) [application/zip]\n",
            "Saving to: ‘Neisseria.gonorrhoeae.zip’\n",
            "\n",
            "Neisseria.gonorrhoe 100%[===================>] 140.85M  10.3MB/s    in 15s     \n",
            "\n",
            "2024-11-15 06:25:52 (9.14 MB/s) - ‘Neisseria.gonorrhoeae.zip’ saved [147695637/147695637]\n",
            "\n",
            "--2024-11-15 06:25:52--  https://doctoral.matinf.uj.edu.pl/database/dibas/Porfyromonas.gingivalis.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 160395445 (153M) [application/zip]\n",
            "Saving to: ‘Porfyromonas.gingivalis.zip’\n",
            "\n",
            "Porfyromonas.gingiv 100%[===================>] 152.96M  10.2MB/s    in 19s     \n",
            "\n",
            "2024-11-15 06:26:12 (8.17 MB/s) - ‘Porfyromonas.gingivalis.zip’ saved [160395445/160395445]\n",
            "\n",
            "--2024-11-15 06:26:12--  https://doctoral.matinf.uj.edu.pl/database/dibas/Propionibacterium.acnes.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 165973803 (158M) [application/zip]\n",
            "Saving to: ‘Propionibacterium.acnes.zip’\n",
            "\n",
            "Propionibacterium.a 100%[===================>] 158.28M  10.1MB/s    in 20s     \n",
            "\n",
            "2024-11-15 06:26:33 (7.81 MB/s) - ‘Propionibacterium.acnes.zip’ saved [165973803/165973803]\n",
            "\n",
            "--2024-11-15 06:26:33--  https://doctoral.matinf.uj.edu.pl/database/dibas/Proteus.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132926714 (127M) [application/zip]\n",
            "Saving to: ‘Proteus.zip’\n",
            "\n",
            "Proteus.zip         100%[===================>] 126.77M  10.2MB/s    in 16s     \n",
            "\n",
            "2024-11-15 06:26:50 (7.94 MB/s) - ‘Proteus.zip’ saved [132926714/132926714]\n",
            "\n",
            "--2024-11-15 06:26:50--  https://doctoral.matinf.uj.edu.pl/database/dibas/Pseudomonas.aeruginosa.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 129310462 (123M) [application/zip]\n",
            "Saving to: ‘Pseudomonas.aeruginosa.zip’\n",
            "\n",
            "Pseudomonas.aerugin 100%[===================>] 123.32M  10.0MB/s    in 14s     \n",
            "\n",
            "2024-11-15 06:27:05 (8.92 MB/s) - ‘Pseudomonas.aeruginosa.zip’ saved [129310462/129310462]\n",
            "\n",
            "--2024-11-15 06:27:05--  https://doctoral.matinf.uj.edu.pl/database/dibas/Staphylococcus.aureus.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124208169 (118M) [application/zip]\n",
            "Saving to: ‘Staphylococcus.aureus.zip’\n",
            "\n",
            "Staphylococcus.aure 100%[===================>] 118.45M  10.4MB/s    in 13s     \n",
            "\n",
            "2024-11-15 06:27:19 (8.91 MB/s) - ‘Staphylococcus.aureus.zip’ saved [124208169/124208169]\n",
            "\n",
            "--2024-11-15 06:27:19--  https://doctoral.matinf.uj.edu.pl/database/dibas/Staphylococcus.epidermidis.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124112717 (118M) [application/zip]\n",
            "Saving to: ‘Staphylococcus.epidermidis.zip’\n",
            "\n",
            "Staphylococcus.epid 100%[===================>] 118.36M  10.4MB/s    in 14s     \n",
            "\n",
            "2024-11-15 06:27:34 (8.59 MB/s) - ‘Staphylococcus.epidermidis.zip’ saved [124112717/124112717]\n",
            "\n",
            "--2024-11-15 06:27:34--  https://doctoral.matinf.uj.edu.pl/database/dibas/Staphylococcus.saprophiticus.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123377786 (118M) [application/zip]\n",
            "Saving to: ‘Staphylococcus.saprophiticus.zip’\n",
            "\n",
            "Staphylococcus.sapr 100%[===================>] 117.66M  10.4MB/s    in 13s     \n",
            "\n",
            "2024-11-15 06:27:48 (8.93 MB/s) - ‘Staphylococcus.saprophiticus.zip’ saved [123377786/123377786]\n",
            "\n",
            "--2024-11-15 06:27:48--  https://doctoral.matinf.uj.edu.pl/database/dibas/Streptococcus.agalactiae.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 126896934 (121M) [application/zip]\n",
            "Saving to: ‘Streptococcus.agalactiae.zip’\n",
            "\n",
            "Streptococcus.agala 100%[===================>] 121.02M  7.65MB/s    in 18s     \n",
            "\n",
            "2024-11-15 06:28:07 (6.90 MB/s) - ‘Streptococcus.agalactiae.zip’ saved [126896934/126896934]\n",
            "\n",
            "--2024-11-15 06:28:07--  https://doctoral.matinf.uj.edu.pl/database/dibas/Veionella.zip\n",
            "Resolving doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)... 149.156.65.236\n",
            "Connecting to doctoral.matinf.uj.edu.pl (doctoral.matinf.uj.edu.pl)|149.156.65.236|:443... connected.\n",
            "WARNING: cannot verify doctoral.matinf.uj.edu.pl's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142905258 (136M) [application/zip]\n",
            "Saving to: ‘Veionella.zip’\n",
            "\n",
            "Veionella.zip       100%[===================>] 136.28M  8.90MB/s    in 16s     \n",
            "\n",
            "2024-11-15 06:28:24 (8.44 MB/s) - ‘Veionella.zip’ saved [142905258/142905258]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Acinetobacter.baumanii.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Actinomyces.israeli.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Bacteroides.fragilis.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Bifidobacterium.spp.zip --no-check-certificate\n",
        "# !wget https://doctoral.matinf.uj.edu.pl/database/dibas/Candida.albicans.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Clostridium.perfringens.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Enterococcus.faecium.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Enterococcus.faecalis.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Escherichia.coli.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Fusobacterium.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.casei.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.crispatus.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.delbrueckii.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.gasseri.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.jehnsenii.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.johnsonii.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.paracasei.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.plantarum.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.reuteri.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.rhamnosus.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Lactobacillus.salivarius.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Listeria.monocytogenes.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Micrococcus.spp.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Neisseria.gonorrhoeae.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Porfyromonas.gingivalis.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Propionibacterium.acnes.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Proteus.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Pseudomonas.aeruginosa.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Staphylococcus.aureus.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Staphylococcus.epidermidis.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Staphylococcus.saprophiticus.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Streptococcus.agalactiae.zip --no-check-certificate\n",
        "!wget https://doctoral.matinf.uj.edu.pl/database/dibas/Veionella.zip --no-check-certificate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjlr02wAwfgv",
        "outputId": "28b336ac-0c01-4358-c497-ecbc5f39c400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'Correct_DIBAS/'\n",
            "/content/Correct_DIBAS\n"
          ]
        }
      ],
      "source": [
        "%cd Correct_DIBAS/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_p15vxNpO_S",
        "outputId": "e4af967f-c2d7-4bae-e343-d2bfdd9cc4ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  Acinetobacter.baumanii.zip\n",
            "   creating: Acinetobacter.baumanii/Acinetobacter.baumanii/\n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0001.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0002.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0003.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0004.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0005.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0006.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0007.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0008.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0009.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0010.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0011.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0012.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0013.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0014.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0015.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0016.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0017.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0018.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0019.tif  \n",
            "  inflating: Acinetobacter.baumanii/Acinetobacter.baumanii/Acinetobacter.baumanii_0020.tif  \n",
            "Archive:  Lactobacillus.delbrueckii.zip\n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0001.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0002.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0003.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0004.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0005.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0006.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0007.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0008.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0009.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0010.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0011.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0012.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0013.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0014.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0015.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0016.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0017.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0018.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0019.tif  \n",
            "  inflating: Lactobacillus.delbrueckii/Lactobacillus.delbrueckii_0020.tif  \n",
            "Archive:  Neisseria.gonorrhoeae.zip\n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0001.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0002.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0003.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0004.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0005.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0006.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0007.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0008.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0009.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0010.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0011.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0012.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0013.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0014.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0015.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0016.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0017.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0018.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0019.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0020.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0021.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0022.tif  \n",
            "  inflating: Neisseria.gonorrhoeae/Neisseria.gonorrhoeae_0023.tif  \n",
            "Archive:  Actinomyces.israeli.zip\n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0001.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0002.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0003.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0004.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0005.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0006.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0007.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0008.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0009.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0010.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0011.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0012.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0013.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0014.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0015.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0016.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0017.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0018.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0019.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0020.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0021.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0022.tif  \n",
            "  inflating: Actinomyces.israeli/Actinomyces.israeli_0023.tif  \n",
            "Archive:  Lactobacillus.gasseri.zip\n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0001.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0002.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0003.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0004.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0005.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0006.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0007.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0008.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0009.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0010.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0011.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0012.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0013.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0014.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0015.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0016.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0017.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0018.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0019.tif  \n",
            "  inflating: Lactobacillus.gasseri/Lactobacillus.gasseri_0020.tif  \n",
            "Archive:  Porfyromonas.gingivalis.zip\n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0001.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0002.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0003.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0004.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0005.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0006.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0007.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0008.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0009.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0010.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0011.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0012.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0013.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0014.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0015.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0016.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0017.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0018.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0019.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0020.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0021.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0022.tif  \n",
            "  inflating: Porfyromonas.gingivalis/Porfyromonas.gingivalis_0023.tif  \n",
            "Archive:  Bacteroides.fragilis.zip\n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0001.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0002.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0003.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0004.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0005.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0006.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0007.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0008.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0009.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0010.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0011.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0012.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0013.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0014.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0015.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0016.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0017.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0018.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0019.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0020.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0021.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0022.tif  \n",
            "  inflating: Bacteroides.fragilis/Bacteroides.fragilis_0023.tif  \n",
            "Archive:  Lactobacillus.jehnsenii.zip\n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0001.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0002.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0003.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0004.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0005.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0006.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0007.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0008.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0009.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0010.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0011.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0012.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0013.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0014.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0015.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0016.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0017.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0018.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0019.tif  \n",
            "  inflating: Lactobacillus.jehnsenii/Lactobacillus.jehnsenii_0020.tif  \n",
            "Archive:  Propionibacterium.acnes.zip\n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0001.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0002.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0003.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0004.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0005.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0006.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0007.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0008.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0009.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0010.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0011.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0012.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0013.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0014.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0015.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0016.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0017.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0018.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0019.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0020.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0021.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0022.tif  \n",
            "  inflating: Propionibacterium.acnes/Propionibacterium.acnes_0023.tif  \n",
            "Archive:  Bifidobacterium.spp.zip\n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0001.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0002.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0003.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0004.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0005.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0006.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0007.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0008.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0009.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0010.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0011.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0012.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0013.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0014.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0015.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0016.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0017.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0018.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0019.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0020.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0021.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0022.tif  \n",
            "  inflating: Bifidobacterium.spp/Bifidobacterium.spp_0023.tif  \n",
            "Archive:  Lactobacillus.johnsonii.zip\n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0001.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0002.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0003.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0004.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0005.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0006.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0007.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0008.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0009.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0010.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0011.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0012.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0013.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0014.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0015.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0016.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0017.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0018.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0019.tif  \n",
            "  inflating: Lactobacillus.johnsonii/Lactobacillus.johnsonii_0020.tif  \n",
            "Archive:  Proteus.zip\n",
            "  inflating: Proteus/Proteus_0001.tif  \n",
            "  inflating: Proteus/Proteus_0002.tif  \n",
            "  inflating: Proteus/Proteus_0003.tif  \n",
            "  inflating: Proteus/Proteus_0004.tif  \n",
            "  inflating: Proteus/Proteus_0005.tif  \n",
            "  inflating: Proteus/Proteus_0006.tif  \n",
            "  inflating: Proteus/Proteus_0007.tif  \n",
            "  inflating: Proteus/Proteus_0008.tif  \n",
            "  inflating: Proteus/Proteus_0009.tif  \n",
            "  inflating: Proteus/Proteus_0010.tif  \n",
            "  inflating: Proteus/Proteus_0011.tif  \n",
            "  inflating: Proteus/Proteus_0012.tif  \n",
            "  inflating: Proteus/Proteus_0013.tif  \n",
            "  inflating: Proteus/Proteus_0014.tif  \n",
            "  inflating: Proteus/Proteus_0015.tif  \n",
            "  inflating: Proteus/Proteus_0016.tif  \n",
            "  inflating: Proteus/Proteus_0017.tif  \n",
            "  inflating: Proteus/Proteus_0018.tif  \n",
            "  inflating: Proteus/Proteus_0019.tif  \n",
            "  inflating: Proteus/Proteus_0020.tif  \n",
            "Archive:  Clostridium.perfringens.zip\n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0001.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0002.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0003.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0004.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0005.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0006.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0007.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0008.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0009.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0010.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0011.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0012.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0013.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0014.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0015.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0016.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0017.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0018.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0019.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0020.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0021.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0022.tif  \n",
            "  inflating: Clostridium.perfringens/Clostridium.perfringens_0023.tif  \n",
            "Archive:  Lactobacillus.paracasei.zip\n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0001.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0002.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0003.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0004.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0005.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0006.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0007.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0008.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0009.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0010.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0011.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0012.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0013.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0014.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0015.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0016.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0017.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0018.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0019.tif  \n",
            "  inflating: Lactobacillus.paracasei/Lactobacillus.paracasei_0020.tif  \n",
            "Archive:  Pseudomonas.aeruginosa.zip\n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0001.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0002.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0003.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0004.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0005.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0006.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0007.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0008.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0009.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0010.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0011.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0012.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0013.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0014.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0015.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0016.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0017.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0018.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0019.tif  \n",
            "  inflating: Pseudomonas.aeruginosa/Pseudomonas.aeruginosa_0020.tif  \n",
            "Archive:  Enterococcus.faecalis.zip\n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0001.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0002.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0003.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0004.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0005.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0006.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0007.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0008.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0009.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0010.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0011.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0012.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0013.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0014.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0015.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0016.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0017.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0018.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0019.tif  \n",
            "  inflating: Enterococcus.faecalis/Enterococcus.faecalis_0020.tif  \n",
            "Archive:  Lactobacillus.plantarum.zip\n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0001.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0002.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0003.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0004.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0005.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0006.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0007.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0008.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0009.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0010.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0011.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0012.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0013.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0014.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0015.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0016.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0017.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0018.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0019.tif  \n",
            "  inflating: Lactobacillus.plantarum/Lactobacillus.plantarum_0020.tif  \n",
            "Archive:  Staphylococcus.aureus.zip\n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0001.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0002.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0003.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0004.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0005.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0006.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0007.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0008.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0009.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0010.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0011.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0012.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0013.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0014.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0015.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0016.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0017.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0018.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0019.tif  \n",
            "  inflating: Staphylococcus.aureus/Staphylococcus.aureus_0020.tif  \n",
            "Archive:  Enterococcus.faecium.zip\n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0001.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0002.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0003.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0004.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0005.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0006.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0007.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0008.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0009.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0010.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0011.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0012.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0013.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0014.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0015.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0016.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0017.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0018.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0019.tif  \n",
            "  inflating: Enterococcus.faecium/Enterococcus.faecium_0020.tif  \n",
            "Archive:  Lactobacillus.reuteri.zip\n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0001.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0002.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0003.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0004.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0005.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0006.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0007.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0008.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0009.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0010.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0011.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0012.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0013.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0014.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0015.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0016.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0017.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0018.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0019.tif  \n",
            "  inflating: Lactobacillus.reuteri/Lactobacillus.reuteri_0020.tif  \n",
            "Archive:  Staphylococcus.epidermidis.zip\n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0001.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0002.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0003.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0004.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0005.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0006.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0007.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0008.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0009.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0010.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0011.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0012.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0013.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0014.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0015.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0016.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0017.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0018.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0019.tif  \n",
            "  inflating: Staphylococcus.epidermidis/Staphylococcus.epidermidis_0020.tif  \n",
            "Archive:  Escherichia.coli.zip\n",
            "  inflating: Escherichia.coli/Escherichia.coli_0001.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0002.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0003.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0004.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0005.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0006.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0007.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0008.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0009.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0010.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0011.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0012.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0013.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0014.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0015.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0016.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0017.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0018.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0019.tif  \n",
            "  inflating: Escherichia.coli/Escherichia.coli_0020.tif  \n",
            "Archive:  Lactobacillus.rhamnosus.zip\n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0001.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0002.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0003.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0004.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0005.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0006.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0007.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0008.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0009.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0010.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0011.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0012.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0013.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0014.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0015.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0016.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0017.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0018.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0019.tif  \n",
            "  inflating: Lactobacillus.rhamnosus/Lactobacillus.rhamnosus_0020.tif  \n",
            "Archive:  Staphylococcus.saprophiticus.zip\n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0001.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0002.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0003.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0004.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0005.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0006.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0007.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0008.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0009.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0010.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0011.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0012.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0013.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0014.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0015.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0016.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0017.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0018.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0019.tif  \n",
            "  inflating: Staphylococcus.saprophiticus/Staphylococcus.saprophiticus_0020.tif  \n",
            "Archive:  Fusobacterium.zip\n",
            "  inflating: Fusobacterium/Fusobacterium_0001.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0002.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0003.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0004.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0005.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0006.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0007.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0008.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0009.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0010.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0011.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0012.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0013.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0014.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0015.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0016.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0017.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0018.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0019.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0020.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0021.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0022.tif  \n",
            "  inflating: Fusobacterium/Fusobacterium_0023.tif  \n",
            "Archive:  Lactobacillus.salivarius.zip\n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0001.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0002.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0003.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0004.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0005.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0006.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0007.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0008.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0009.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0010.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0011.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0012.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0013.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0014.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0015.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0016.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0017.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0018.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0019.tif  \n",
            "  inflating: Lactobacillus.salivarius/Lactobacillus.salivarius_0020.tif  \n",
            "Archive:  Streptococcus.agalactiae.zip\n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0001.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0002.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0003.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0004.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0005.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0006.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0007.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0008.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0009.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0010.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0011.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0012.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0013.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0014.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0015.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0016.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0017.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0018.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0019.tif  \n",
            "  inflating: Streptococcus.agalactiae/Streptococcus.agalactiae_0020.tif  \n",
            "Archive:  Lactobacillus.casei.zip\n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0001.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0002.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0003.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0004.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0005.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0006.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0007.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0008.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0009.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0010.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0011.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0012.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0013.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0014.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0015.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0016.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0017.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0018.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0019.tif  \n",
            "  inflating: Lactobacillus.casei/Lactobacillus.casei_0020.tif  \n",
            "Archive:  Listeria.monocytogenes.zip\n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0001.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0002.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0003.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0004.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0005.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0006.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0007.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0008.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0009.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0010.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0011.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0012.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0013.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0014.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0015.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0016.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0017.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0018.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0019.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0020.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0021.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0022.tif  \n",
            "  inflating: Listeria.monocytogenes/Listeria.monocytogenes_0023.tif  \n",
            "Archive:  Veionella.zip\n",
            "  inflating: Veionella/Veionella_0001.tif  \n",
            "  inflating: Veionella/Veionella_0002.tif  \n",
            "  inflating: Veionella/Veionella_0003.tif  \n",
            "  inflating: Veionella/Veionella_0004.tif  \n",
            "  inflating: Veionella/Veionella_0005.tif  \n",
            "  inflating: Veionella/Veionella_0006.tif  \n",
            "  inflating: Veionella/Veionella_0007.tif  \n",
            "  inflating: Veionella/Veionella_0008.tif  \n",
            "  inflating: Veionella/Veionella_0009.tif  \n",
            "  inflating: Veionella/Veionella_0010.tif  \n",
            "  inflating: Veionella/Veionella_0011.tif  \n",
            "  inflating: Veionella/Veionella_0012.tif  \n",
            "  inflating: Veionella/Veionella_0013.tif  \n",
            "  inflating: Veionella/Veionella_0014.tif  \n",
            "  inflating: Veionella/Veionella_0015.tif  \n",
            "  inflating: Veionella/Veionella_0016.tif  \n",
            "  inflating: Veionella/Veionella_0017.tif  \n",
            "  inflating: Veionella/Veionella_0018.tif  \n",
            "  inflating: Veionella/Veionella_0019.tif  \n",
            "  inflating: Veionella/Veionella_0020.tif  \n",
            "  inflating: Veionella/Veionella_0021.tif  \n",
            "  inflating: Veionella/Veionella_0022.tif  \n",
            "Archive:  Lactobacillus.crispatus.zip\n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0001.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0002.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0003.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0004.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0005.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0006.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0007.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0008.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0009.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0010.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0011.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0012.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0013.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0014.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0015.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0016.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0017.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0018.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0019.tif  \n",
            "  inflating: Lactobacillus.crispatus/Lactobacillus.crispatus_0020.tif  \n",
            "Archive:  Micrococcus.spp.zip\n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0001.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0002.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0003.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0004.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0005.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0006.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0007.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0008.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0009.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0010.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0011.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0012.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0013.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0014.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0015.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0016.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0017.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0018.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0019.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0020.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0021.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0022.tif  \n",
            "  inflating: Micrococcus.spp/Micrococcus.spp_0023.tif  \n"
          ]
        }
      ],
      "source": [
        "! unzip Acinetobacter.baumanii.zip -d Acinetobacter.baumanii\n",
        "! unzip Lactobacillus.delbrueckii.zip -d Lactobacillus.delbrueckii\n",
        "! unzip Neisseria.gonorrhoeae.zip -d Neisseria.gonorrhoeae\n",
        "! unzip Actinomyces.israeli.zip -d Actinomyces.israeli\n",
        "! unzip Lactobacillus.gasseri.zip -d Lactobacillus.gasseri\n",
        "! unzip Porfyromonas.gingivalis.zip -d Porfyromonas.gingivalis\n",
        "! unzip Bacteroides.fragilis.zip -d Bacteroides.fragilis\n",
        "! unzip Lactobacillus.jehnsenii.zip -d Lactobacillus.jehnsenii\n",
        "! unzip Propionibacterium.acnes.zip -d Propionibacterium.acnes\n",
        "! unzip Bifidobacterium.spp.zip -d Bifidobacterium.spp\n",
        "! unzip Lactobacillus.johnsonii.zip -d Lactobacillus.johnsonii\n",
        "! unzip Proteus.zip -d Proteus\n",
        "! unzip Clostridium.perfringens.zip -d Clostridium.perfringens\n",
        "! unzip Lactobacillus.paracasei.zip -d Lactobacillus.paracasei\n",
        "! unzip Pseudomonas.aeruginosa.zip -d Pseudomonas.aeruginosa\n",
        "! unzip Enterococcus.faecalis.zip -d Enterococcus.faecalis\n",
        "! unzip Lactobacillus.plantarum.zip -d Lactobacillus.plantarum\n",
        "! unzip Staphylococcus.aureus.zip -d Staphylococcus.aureus\n",
        "! unzip Enterococcus.faecium.zip -d Enterococcus.faecium\n",
        "! unzip Lactobacillus.reuteri.zip -d Lactobacillus.reuteri\n",
        "! unzip Staphylococcus.epidermidis.zip -d Staphylococcus.epidermidis\n",
        "! unzip Escherichia.coli.zip -d Escherichia.coli\n",
        "! unzip Lactobacillus.rhamnosus.zip -d Lactobacillus.rhamnosus\n",
        "! unzip Staphylococcus.saprophiticus.zip -d Staphylococcus.saprophiticus\n",
        "! unzip Fusobacterium.zip -d Fusobacterium\n",
        "! unzip Lactobacillus.salivarius.zip -d Lactobacillus.salivarius\n",
        "! unzip Streptococcus.agalactiae.zip -d Streptococcus.agalactiae\n",
        "! unzip Lactobacillus.casei.zip -d Lactobacillus.casei\n",
        "! unzip Listeria.monocytogenes.zip -d Listeria.monocytogenes\n",
        "! unzip Veionella.zip -d Veionella\n",
        "! unzip Lactobacillus.crispatus.zip -d Lactobacillus.crispatus\n",
        "! unzip Micrococcus.spp.zip -d Micrococcus.spp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkstFsUWrmTk",
        "outputId": "e110ff23-53ce-4002-bbf2-c0653fc9077a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J7M31tagTugT"
      },
      "outputs": [],
      "source": [
        "# Imports here\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torchvision import datasets, transforms, models\n",
        "from pytorch_model_summary import summary\n",
        "\n",
        "# # Archs not in Pytorch\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# External functions\n",
        "from scripts.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbyy23lyTugU",
        "outputId": "aa2d455c-00b9-4058-f122-d3d936dd184f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu124\n",
            "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "\n",
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npL5_ECHTugV"
      },
      "source": [
        "## Data paths and hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPkZcCI_TugV"
      },
      "source": [
        "#### Hyperparameters and dataset details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ioU4uhXyTugV"
      },
      "outputs": [],
      "source": [
        "# Dataset details\n",
        "dataset_version = 'original' # original or augmented\n",
        "img_shape = (224,224)\n",
        "img_size = str(img_shape[0])+\"x\"+str(img_shape[1])\n",
        "\n",
        "# Root directory of dataset\n",
        "data_dir = 'Correct_DIBAS/'\n",
        "\n",
        "train_batch_size = 32\n",
        "val_test_batch_size = 32\n",
        "feature_extract = False\n",
        "pretrained = True\n",
        "h_epochs = 15\n",
        "kfolds = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp6ake2lTugV"
      },
      "source": [
        "## Data preparation and loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGW77S3kIkCJ"
      },
      "source": [
        "#### Deleting Corrupted files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1hxQ_Z3efrXE"
      },
      "outputs": [],
      "source": [
        "# Check for corrupted TIF files\n",
        "\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    for file in files:\n",
        "        if file == '.ipynb_checkpoints':\n",
        "            continue\n",
        "        if file.endswith('.tif'):\n",
        "            try:\n",
        "                image = Image.open(os.path.join(root, file)) # open the image file\n",
        "                image.verify() # verify that it is, in fact an image\n",
        "\n",
        "            except (IOError, SyntaxError, ValueError) as e:\n",
        "                print('Bad file:', os.path.join(root, file)) # print out the names of corrupt files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QhReumiahqfN"
      },
      "outputs": [],
      "source": [
        "! rm -rf Correct_DIBAS/Micrococcus.spp/Micrococcus.spp_0021.tif\n",
        "! rm -rf Correct_DIBAS/Micrococcus.spp/Micrococcus.spp_0023.tif\n",
        "! rm -rf Correct_DIBAS/Listeria.monocytogenes/Listeria.monocytogenes_0023.tif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xagkLcXpTugV"
      },
      "source": [
        "#### Defining transforms and creating dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LhiyEBx9TugW"
      },
      "outputs": [],
      "source": [
        "# Define transforms for input data\n",
        "training_transforms = transforms.Compose([transforms.Resize((224,224), Image.LANCZOS),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                               [0.229, 0.224, 0.225])])\n",
        "\n",
        "total_set = datasets.ImageFolder(data_dir, transform=training_transforms)\n",
        "\n",
        "# Defining folds\n",
        "splits = KFold(n_splits = kfolds, shuffle = True, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZrX2WtBTugW"
      },
      "source": [
        "#### Visualizing the target classes in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nxeZQOwTugW",
        "outputId": "e4abf574-f6c5-4516-b28b-52ecb5bfe6ec",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n",
            "{0: 'Acinetobacter.baumanii', 1: 'Actinomyces.israeli', 2: 'Bacteroides.fragilis', 3: 'Bifidobacterium.spp', 4: 'Clostridium.perfringens', 5: 'Enterococcus.faecalis', 6: 'Enterococcus.faecium', 7: 'Escherichia.coli', 8: 'Fusobacterium', 9: 'Lactobacillus.casei', 10: 'Lactobacillus.crispatus', 11: 'Lactobacillus.delbrueckii', 12: 'Lactobacillus.gasseri', 13: 'Lactobacillus.jehnsenii', 14: 'Lactobacillus.johnsonii', 15: 'Lactobacillus.paracasei', 16: 'Lactobacillus.plantarum', 17: 'Lactobacillus.reuteri', 18: 'Lactobacillus.rhamnosus', 19: 'Lactobacillus.salivarius', 20: 'Listeria.monocytogenes', 21: 'Micrococcus.spp', 22: 'Neisseria.gonorrhoeae', 23: 'Porfyromonas.gingivalis', 24: 'Propionibacterium.acnes', 25: 'Proteus', 26: 'Pseudomonas.aeruginosa', 27: 'Staphylococcus.aureus', 28: 'Staphylococcus.epidermidis', 29: 'Staphylococcus.saprophiticus', 30: 'Streptococcus.agalactiae', 31: 'Veionella'}\n"
          ]
        }
      ],
      "source": [
        "train_labels = {value : key for (key, value) in total_set.class_to_idx.items()}\n",
        "\n",
        "print(len(train_labels))\n",
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pUjcPMlTugW"
      },
      "source": [
        "## Model definition and initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrsWm2ETugW"
      },
      "source": [
        "#### Freezing pre-trained parameters, finetunning the classifier to output 32 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1tlUB9iQTugW"
      },
      "outputs": [],
      "source": [
        "# Freeze pretrained model parameters to avoid backpropogating through them\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        print(\"Setting grad to false.\")\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_device():\n",
        "    # Model and criterion to GPU\n",
        "    if torch.cuda.is_available():\n",
        "        return 'cuda'\n",
        "    else:\n",
        "        return 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpaZpumBI6Ra"
      },
      "source": [
        "## Model (CNN + Tranformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "u9vsuLxlW_HB"
      },
      "outputs": [],
      "source": [
        "def to_3d(x):\n",
        "    return rearrange(x, 'b c h w -> b (h w) c')\n",
        "\n",
        "def to_4d(x,h,w):\n",
        "    return rearrange(x, 'b (h w) c -> b c h w',h=h,w=w)\n",
        "\n",
        "class BiasFree_LayerNorm(nn.Module):\n",
        "    def __init__(self, normalized_shape):\n",
        "        super(BiasFree_LayerNorm, self).__init__()\n",
        "        if isinstance(normalized_shape, numbers.Integral):\n",
        "            normalized_shape = (normalized_shape,)\n",
        "        normalized_shape = torch.Size(normalized_shape)\n",
        "\n",
        "        assert len(normalized_shape) == 1\n",
        "\n",
        "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
        "        self.normalized_shape = normalized_shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        sigma = x.var(-1, keepdim=True, unbiased=False)\n",
        "        return x / torch.sqrt(sigma+1e-5) * self.weight\n",
        "\n",
        "class WithBias_LayerNorm(nn.Module):\n",
        "    def __init__(self, normalized_shape):\n",
        "        super(WithBias_LayerNorm, self).__init__()\n",
        "        if isinstance(normalized_shape, numbers.Integral):\n",
        "            normalized_shape = (normalized_shape,)\n",
        "        normalized_shape = torch.Size(normalized_shape)\n",
        "\n",
        "        assert len(normalized_shape) == 1\n",
        "\n",
        "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
        "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
        "        self.normalized_shape = normalized_shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu = x.mean(-1, keepdim=True)\n",
        "        sigma = x.var(-1, keepdim=True, unbiased=False)\n",
        "        return (x - mu) / torch.sqrt(sigma+1e-5) * self.weight + self.bias\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim, LayerNorm_type):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        if LayerNorm_type =='BiasFree':\n",
        "            self.body = BiasFree_LayerNorm(dim)\n",
        "        else:\n",
        "            self.body = WithBias_LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.shape[-2:]\n",
        "        return to_4d(self.body(to_3d(x)), h, w)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, ffn_expansion_factor, bias):\n",
        "        super(FeedForward, self).__init__()\n",
        "\n",
        "        hidden_features = int(dim*ffn_expansion_factor)\n",
        "\n",
        "        self.project_in = nn.Conv2d(dim, hidden_features*2, kernel_size=1, bias=bias)\n",
        "\n",
        "        self.dwconv = nn.Conv2d(hidden_features*2, hidden_features*2, kernel_size=3, stride=1, padding=1, groups=hidden_features*2, bias=bias)\n",
        "\n",
        "        self.project_out = nn.Conv2d(hidden_features, dim, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.project_in(x)\n",
        "        x1, x2 = self.dwconv(x).chunk(2, dim=1)\n",
        "        x = F.gelu(x1) * x2\n",
        "        x = self.project_out(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, bias=False):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        # Initialize ScaledDotProduct attention\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = ScaledDotProduct(\n",
        "            dropout=0.1\n",
        "        )\n",
        "\n",
        "        # MLP (feedforward network) from Xformers\n",
        "        # self.ffn = MLP(\n",
        "        #     dim_model=embed_dim,\n",
        "        #     dropout=0.1,\n",
        "        #     activation=\"relu\",\n",
        "        #     hidden_layer_multiplier=4\n",
        "        # )\n",
        "\n",
        "        self.ffn = FeedForward(embed_dim, ffn_expansion_factor=2.66, bias=bias)\n",
        "\n",
        "        # Layer normalization\n",
        "        self.norm1 = LayerNorm(embed_dim, 'WithBias')\n",
        "        self.norm2 = LayerNorm(embed_dim, 'WithBias')\n",
        "\n",
        "        # Convolutional layers for QKV projections\n",
        "        self.qkv = nn.Conv2d(embed_dim, embed_dim*3, kernel_size=1, bias=bias)\n",
        "        self.qkv_dwconv = nn.Conv2d(embed_dim*3, embed_dim*3, kernel_size=3, stride=1, padding=1, groups=embed_dim*3, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.qkv_dwconv(self.qkv(x))\n",
        "        q, k, v = qkv.chunk(3, dim=1)  # Split into query, key, value\n",
        "\n",
        "        # Reshaping for multi-head attention\n",
        "        q = rearrange(q, 'b (head c) h w -> b head c (h w)', head=self.num_heads)\n",
        "        k = rearrange(k, 'b (head c) h w -> b head c (h w)', head=self.num_heads)\n",
        "        v = rearrange(v, 'b (head c) h w -> b head c (h w)', head=self.num_heads)\n",
        "\n",
        "        q = torch.nn.functional.normalize(q, dim=-1)\n",
        "        k = torch.nn.functional.normalize(k, dim=-1)\n",
        "\n",
        "        # Apply ScaledDotProduct attention\n",
        "        attn_output = self.attention(q, k, v)\n",
        "\n",
        "        # Reshape attention output to match input shape for residual connection\n",
        "        # Ensure the flattened spatial dimensions match\n",
        "\n",
        "        attn_output = rearrange(attn_output, 'b head c (h w) -> b (head c) h w', head=self.num_heads, h=h, w=w)\n",
        "\n",
        "        # Add residual connection and layer normalization\n",
        "        x = x + attn_output\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # x = x.flatten(2)  # Flatten spatial dimensions (height and width)\n",
        "        # x = x.transpose(1, 2)  # Change shape to [batch_size, features, N] for MLP (N = height * width)\n",
        "\n",
        "        # Apply FFN with residual connection\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = x + ffn_output\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class MobileNetTransformer(nn.Module):\n",
        "    def __init__(self, num_classes=1000, num_heads=4, embed_dim=128):\n",
        "        super(MobileNetTransformer, self).__init__()\n",
        "\n",
        "        # Load MobileNetV2\n",
        "        self.mobilenet = mobilenet_v2(pretrained=True)\n",
        "        self.mobilenet.classifier = nn.Identity()  # Remove classifier layer\n",
        "\n",
        "        # Freeze Mobilenet Weight\n",
        "        for param in self.mobilenet.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Define the output channels for each MobileNetV2 block based on your previous output\n",
        "        block_output_channels = [\n",
        "            32, 16, 24, 24, 32, 32, 32, 64, 64, 64, 64, 96, 96, 96, 160, 160, 160, 320, 1280\n",
        "        ]\n",
        "\n",
        "        # Create transformer blocks to match MobileNetV2 block structure\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(embed_dim=block_output_channels[i], num_heads=num_heads)\n",
        "            for i in range(len(self.mobilenet.features))\n",
        "        ])\n",
        "\n",
        "        # Final classification layer\n",
        "        self.fc = nn.Linear(block_output_channels[-1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, mobilenet_block in enumerate(self.mobilenet.features):\n",
        "            # Apply MobileNetV2 block\n",
        "            x = mobilenet_block(x)\n",
        "\n",
        "            # Get the number of output channels for this block\n",
        "            # batch_size, channels, height, width = x.size()\n",
        "\n",
        "            # Flatten to prepare for transformer input if necessary\n",
        "            # x = x.view(batch_size, channels, height * width).transpose(1, 2)  # Shape [B, N, C]\n",
        "\n",
        "            # Apply corresponding Transformer block\n",
        "            x = self.transformer_blocks[i](x)\n",
        "\n",
        "            # Reshape back to image format for the next MobileNetV2 block\n",
        "            # x = x.transpose(1, 2).view(batch_size, channels, height, width)\n",
        "\n",
        "        # Global average pooling for classification\n",
        "        x = x.mean(dim=[2, 3])  # Shape [B, C]\n",
        "        x = self.fc(x)  # Shape [B, num_classes]\n",
        "        return x\n",
        "\n",
        "# # Instantiate and test the model\n",
        "# model = MobileNetTransformer(num_classes=32, num_heads=4, embed_dim=128)\n",
        "# sample_input = torch.randn(1, 3, 224, 224)\n",
        "# output = model(sample_input)\n",
        "# print(output.shape)  # Should be [1, 32]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNRaLfoqzL7H",
        "outputId": "37d0cc98-7126-49e6-e245-11755e2336ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IPmr0bkQTugX"
      },
      "outputs": [],
      "source": [
        "def load_model():\n",
        "    # Transfer Learning\n",
        "    model = MobileNetTransformer(num_classes=32, num_heads=4, embed_dim=48)\n",
        "\n",
        "    # Mode\n",
        "    # model = set_parameter_requires_grad(model, feature_extract)\n",
        "\n",
        "    # Fine tuning\n",
        "    # Build custom classifier\n",
        "    # model._fc = nn.Linear(in_features=1280,\n",
        "    #                     out_features=32)\n",
        "    return model\n",
        "\n",
        "def create_optimizer(model):\n",
        "    # Parameters to update\n",
        "    params_to_update = model.parameters()\n",
        "\n",
        "    if feature_extract:\n",
        "        params_to_update = []\n",
        "        for param in model.parameters():\n",
        "            if param.requires_grad == True:\n",
        "                params_to_update.append(param)\n",
        "\n",
        "    else:\n",
        "        n_params = 0\n",
        "        for param in model.parameters():\n",
        "            if param.requires_grad == True:\n",
        "                n_params += 1\n",
        "\n",
        "\n",
        "    # Loss function and gradient descent\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = optim.Adam(params_to_update,\n",
        "                          lr=0.001,\n",
        "                          weight_decay=0.000004)\n",
        "\n",
        "    return criterion.to(get_device()), model.to(get_device()), optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw3LAaAATugX"
      },
      "source": [
        "## Training, validation and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sI9c6OCOLpSM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "save_dir = '/content/models'\n",
        "os.makedirs(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jzQsOm61TugX",
        "outputId": "34229ba1-bbd3-4cfb-c155-61ced5d9775a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold : 0\n",
            "Samples in training: 602\n",
            "Samples in test: 67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 180MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
            "  deprecated_function(self)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------\n",
            "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
            "=============================================================================\n",
            "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
            "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
            "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
            "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
            "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
            "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
            "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
            "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
            "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
            "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
            "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
            "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
            "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
            "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
            "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
            "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
            "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
            "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
            "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
            "             Linear-20               [1, 32]          40,992          40,992\n",
            "=============================================================================\n",
            "Total params: 20,759,318\n",
            "Trainable params: 20,759,318\n",
            "Non-trainable params: 0\n",
            "-----------------------------------------------------------------------------\n",
            "\t\t Training: Epoch(0) - Loss: 1.6828, Acc: 57.8073\n",
            "\t\t Validation(0) - Loss: 1.5916, Acc: 56.7164\n",
            "Model for Fold 0, Epoch 0 saved at /content/models/model_fold_0_epoch_0.pth\n",
            "\t\t Training: Epoch(1) - Loss: 0.5420, Acc: 83.7209\n",
            "\t\t Validation(1) - Loss: 0.6157, Acc: 80.5970\n",
            "Model for Fold 0, Epoch 1 saved at /content/models/model_fold_0_epoch_1.pth\n",
            "\t\t Training: Epoch(2) - Loss: 0.3975, Acc: 88.3721\n",
            "\t\t Validation(2) - Loss: 0.5027, Acc: 86.5672\n",
            "Model for Fold 0, Epoch 2 saved at /content/models/model_fold_0_epoch_2.pth\n",
            "\t\t Training: Epoch(3) - Loss: 0.2018, Acc: 93.3555\n",
            "\t\t Validation(3) - Loss: 0.2631, Acc: 94.0299\n",
            "Model for Fold 0, Epoch 3 saved at /content/models/model_fold_0_epoch_3.pth\n",
            "\t\t Training: Epoch(4) - Loss: 0.2469, Acc: 94.1860\n",
            "\t\t Validation(4) - Loss: 0.1893, Acc: 92.5373\n",
            "Model for Fold 0, Epoch 4 saved at /content/models/model_fold_0_epoch_4.pth\n",
            "\t\t Training: Epoch(5) - Loss: 0.0991, Acc: 95.8472\n",
            "\t\t Validation(5) - Loss: 0.2548, Acc: 92.5373\n",
            "Model for Fold 0, Epoch 5 saved at /content/models/model_fold_0_epoch_5.pth\n",
            "\t\t Training: Epoch(6) - Loss: 0.1130, Acc: 97.3422\n",
            "\t\t Validation(6) - Loss: 0.4016, Acc: 92.5373\n",
            "Model for Fold 0, Epoch 6 saved at /content/models/model_fold_0_epoch_6.pth\n",
            "\t\t Training: Epoch(7) - Loss: 0.1601, Acc: 96.8439\n",
            "\t\t Validation(7) - Loss: 0.1730, Acc: 97.0149\n",
            "Model for Fold 0, Epoch 7 saved at /content/models/model_fold_0_epoch_7.pth\n",
            "\t\t Training: Epoch(8) - Loss: 0.0529, Acc: 98.0066\n",
            "\t\t Validation(8) - Loss: 0.0856, Acc: 97.0149\n",
            "Model for Fold 0, Epoch 8 saved at /content/models/model_fold_0_epoch_8.pth\n",
            "\t\t Training: Epoch(9) - Loss: 0.1157, Acc: 96.8439\n",
            "\t\t Validation(9) - Loss: 0.0835, Acc: 97.0149\n",
            "Model for Fold 0, Epoch 9 saved at /content/models/model_fold_0_epoch_9.pth\n",
            "\t\t Training: Epoch(10) - Loss: 0.0635, Acc: 98.3389\n",
            "\t\t Validation(10) - Loss: 0.4850, Acc: 89.5522\n",
            "Model for Fold 0, Epoch 10 saved at /content/models/model_fold_0_epoch_10.pth\n",
            "\t\t Training: Epoch(11) - Loss: 0.0855, Acc: 97.6744\n",
            "\t\t Validation(11) - Loss: 0.1246, Acc: 95.5224\n",
            "Model for Fold 0, Epoch 11 saved at /content/models/model_fold_0_epoch_11.pth\n",
            "\t\t Training: Epoch(12) - Loss: 0.0460, Acc: 98.5050\n",
            "\t\t Validation(12) - Loss: 0.1332, Acc: 95.5224\n",
            "Model for Fold 0, Epoch 12 saved at /content/models/model_fold_0_epoch_12.pth\n",
            "\t\t Training: Epoch(13) - Loss: 0.0188, Acc: 99.3355\n",
            "\t\t Validation(13) - Loss: 0.1111, Acc: 97.0149\n",
            "Model for Fold 0, Epoch 13 saved at /content/models/model_fold_0_epoch_13.pth\n",
            "\t\t Training: Epoch(14) - Loss: 0.0391, Acc: 98.8372\n",
            "\t\t Validation(14) - Loss: 0.1114, Acc: 94.0299\n",
            "Model for Fold 0, Epoch 14 saved at /content/models/model_fold_0_epoch_14.pth\n",
            "Finished.\n",
            "Total time per fold: 742.6733620166779 seconds.\n",
            "Fold : 1\n",
            "Samples in training: 602\n",
            "Samples in test: 67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
            "  deprecated_function(self)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------\n",
            "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
            "=============================================================================\n",
            "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
            "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
            "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
            "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
            "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
            "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
            "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
            "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
            "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
            "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
            "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
            "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
            "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
            "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
            "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
            "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
            "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
            "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
            "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
            "             Linear-20               [1, 32]          40,992          40,992\n",
            "=============================================================================\n",
            "Total params: 20,759,318\n",
            "Trainable params: 20,759,318\n",
            "Non-trainable params: 0\n",
            "-----------------------------------------------------------------------------\n",
            "\t\t Training: Epoch(0) - Loss: 1.6057, Acc: 56.9767\n",
            "\t\t Validation(0) - Loss: 1.6855, Acc: 56.7164\n",
            "Model for Fold 1, Epoch 0 saved at /content/models/model_fold_1_epoch_0.pth\n",
            "\t\t Training: Epoch(1) - Loss: 0.4787, Acc: 85.2159\n",
            "\t\t Validation(1) - Loss: 0.2025, Acc: 94.0299\n",
            "Model for Fold 1, Epoch 1 saved at /content/models/model_fold_1_epoch_1.pth\n",
            "\t\t Training: Epoch(2) - Loss: 0.3078, Acc: 90.1993\n",
            "\t\t Validation(2) - Loss: 0.2461, Acc: 89.5522\n",
            "Model for Fold 1, Epoch 2 saved at /content/models/model_fold_1_epoch_2.pth\n",
            "\t\t Training: Epoch(3) - Loss: 0.2057, Acc: 92.6910\n",
            "\t\t Validation(3) - Loss: 0.1186, Acc: 95.5224\n",
            "Model for Fold 1, Epoch 3 saved at /content/models/model_fold_1_epoch_3.pth\n",
            "\t\t Training: Epoch(4) - Loss: 0.1561, Acc: 96.5116\n",
            "\t\t Validation(4) - Loss: 0.2649, Acc: 89.5522\n",
            "Model for Fold 1, Epoch 4 saved at /content/models/model_fold_1_epoch_4.pth\n",
            "\t\t Training: Epoch(5) - Loss: 0.1843, Acc: 94.3522\n",
            "\t\t Validation(5) - Loss: 0.1921, Acc: 92.5373\n",
            "Model for Fold 1, Epoch 5 saved at /content/models/model_fold_1_epoch_5.pth\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-58b0e8725b56>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtrunning_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 )\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Variables to store fold scores\n",
        "train_acc = []\n",
        "test_top1_acc = []\n",
        "test_top5_acc = []\n",
        "test_precision = []\n",
        "test_recall = []\n",
        "test_f1 = []\n",
        "times = []\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(splits.split(total_set)):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    print('Fold : {}'.format(fold))\n",
        "\n",
        "    # Train and val samplers\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    print(\"Samples in training:\", len(train_sampler))\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "    print(\"Samples in test:\", len(valid_sampler))\n",
        "\n",
        "    # Train and val loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "                      total_set, batch_size=train_batch_size, sampler=train_sampler)\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "                      total_set, batch_size=1, sampler=valid_sampler)\n",
        "\n",
        "    device = get_device()\n",
        "\n",
        "    criterion, model, optimizer = create_optimizer(load_model())\n",
        "\n",
        "    # Print Model Summary\n",
        "    print(summary(model, torch.zeros(1, 3, 224, 224).cuda()))\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(h_epochs):\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        trunning_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += (preds == labels).sum()\n",
        "            trunning_corrects += preds.size(0)\n",
        "\n",
        "\n",
        "        epoch_loss = running_loss / trunning_corrects\n",
        "        epoch_acc = (running_corrects.double()*100) / trunning_corrects\n",
        "        train_acc.append(epoch_acc.item())\n",
        "\n",
        "        print('\\t\\t Training: Epoch({}) - Loss: {:.4f}, Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
        "\n",
        "        # Validation\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        vrunning_loss = 0.0\n",
        "        vrunning_corrects = 0\n",
        "        num_samples = 0\n",
        "\n",
        "        for data, labels in valid_loader:\n",
        "\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(data)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            vrunning_loss += loss.item() * data.size(0)\n",
        "            vrunning_corrects += (preds == labels).sum()\n",
        "            num_samples += preds.size(0)\n",
        "\n",
        "        vepoch_loss = vrunning_loss/num_samples\n",
        "        vepoch_acc = (vrunning_corrects.double() * 100)/num_samples\n",
        "\n",
        "        print('\\t\\t Validation({}) - Loss: {:.4f}, Acc: {:.4f}'.format(epoch, vepoch_loss, vepoch_acc))\n",
        "\n",
        "        # Save Models\n",
        "        model_save_path = os.path.join(save_dir, f\"model_fold_{fold}_epoch_{epoch}.pth\")\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        print(f\"Model for Fold {fold}, Epoch {epoch} saved at {model_save_path}\")\n",
        "\n",
        "    # Calculating and appending scores to this fold\n",
        "    model.class_to_idx = total_set.class_to_idx\n",
        "    scores = get_scores(model, valid_loader)\n",
        "\n",
        "    test_top1_acc.append(scores[0])\n",
        "    test_top5_acc.append(scores[1])\n",
        "    test_precision.append(scores[2])\n",
        "    test_recall.append(scores[3])\n",
        "    test_f1.append(scores[4])\n",
        "\n",
        "    time_fold = time.time() - start_time\n",
        "    times.append(time_fold)\n",
        "    print(\"Total time per fold: %s seconds.\" %(time_fold))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDm23WYmTugX",
        "outputId": "98f16fd2-8bb3-4449-f0e2-a45eb9efe0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy average:  0.9274636295949993\n",
            "Top-1 test accuracy average:  0.9317561807331629\n",
            "Top-5 test accuracy average:  0.9942028985507246\n",
            "Weighted Precision test accuracy average:  0.9483380695273278\n",
            "Weighted Recall test accuracy average:  0.9317561807331629\n",
            "Weighted F1 test accuracy average:  0.9319668660173775\n",
            "Average time per fold (seconds): 654.8511736869812\n"
          ]
        }
      ],
      "source": [
        "print(\"Train accuracy average: \", np.mean(train_acc) / 100)\n",
        "print(\"Top-1 test accuracy average: \", np.mean(test_top1_acc))\n",
        "print(\"Top-5 test accuracy average: \", np.mean(test_top5_acc))\n",
        "print(\"Weighted Precision test accuracy average: \", np.mean(test_precision))\n",
        "print(\"Weighted Recall test accuracy average: \", np.mean(test_recall))\n",
        "print(\"Weighted F1 test accuracy average: \", np.mean(test_f1))\n",
        "print(\"Average time per fold (seconds):\", np.mean(times))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU7uNWLJMbeV",
        "outputId": "a4f27cdd-8aec-4cf0-8d0f-7bef3f3a89da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "mPqODCYrMbbb",
        "outputId": "3c1bbd6e-691a-4b02-b18e-5778927ac307"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
            "  deprecated_function(self)\n",
            "<ipython-input-41-9949ff7b950a>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://54e6813a3fb6a6c743.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://54e6813a3fb6a6c743.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://54e6813a3fb6a6c743.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Load the best model\n",
        "def load_best_model(path):\n",
        "    model = MobileNetTransformer(num_classes=32, num_heads=4, embed_dim=48)\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Convert TIFF bytes to JPG for preview, then classify using the original TIFF data\n",
        "def handle_upload(tiff_file):\n",
        "    # Convert bytes to an image for both preview and processing\n",
        "    tiff_bytes = io.BytesIO(tiff_file)  # Wrap bytes in a BytesIO object for PIL\n",
        "\n",
        "    # Convert TIFF to JPG for preview\n",
        "    with Image.open(tiff_bytes) as img:\n",
        "        img_jpg = img.convert(\"RGB\")\n",
        "        jpg_buffer = io.BytesIO()\n",
        "        img_jpg.save(jpg_buffer, format=\"JPEG\")\n",
        "        jpg_buffer.seek(0)\n",
        "        preview_image = Image.open(jpg_buffer)\n",
        "\n",
        "    # Rewind the BytesIO object for original TIFF classification\n",
        "    tiff_bytes.seek(0)\n",
        "    with Image.open(tiff_bytes) as original_img:\n",
        "        image = training_transforms(original_img).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            outputs = best_model(image.to(get_device()))\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "    return preview_image, train_labels[predicted.item()]  # Return JPG preview and label\n",
        "\n",
        "# Load the model\n",
        "best_model_path = \"models/model_fold_0_epoch_14.pth\"\n",
        "best_model = load_best_model(best_model_path).to(get_device())\n",
        "\n",
        "# Gradio interface setup\n",
        "with gr.Blocks() as gr_interface:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            file_input = gr.File(type=\"binary\", label=\"Upload TIFF File\")\n",
        "            image_preview = gr.Image(type=\"pil\", label=\"Preview (JPG)\", interactive=False)\n",
        "        label_output = gr.Textbox(label=\"Prediction\")\n",
        "\n",
        "    file_input.change(handle_upload, inputs=file_input, outputs=[image_preview, label_output])\n",
        "\n",
        "gr_interface.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full Train Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-qOXLoxMbY3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Fold : 0\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.6021, Acc: 55.9677\n",
        "\t\t Validation(0) - Loss: 1.7764, Acc: 59.4203\n",
        "\t\t Training: Epoch(1) - Loss: 0.3163, Acc: 89.8387\n",
        "\t\t Validation(1) - Loss: 0.8265, Acc: 81.1594\n",
        "\t\t Training: Epoch(2) - Loss: 0.3694, Acc: 88.8710\n",
        "\t\t Validation(2) - Loss: 0.3940, Acc: 86.9565\n",
        "\t\t Training: Epoch(3) - Loss: 0.1728, Acc: 94.8387\n",
        "\t\t Validation(3) - Loss: 0.3483, Acc: 89.8551\n",
        "\t\t Training: Epoch(4) - Loss: 0.1557, Acc: 94.8387\n",
        "\t\t Validation(4) - Loss: 0.5214, Acc: 88.4058\n",
        "\t\t Training: Epoch(5) - Loss: 0.1412, Acc: 94.8387\n",
        "\t\t Validation(5) - Loss: 0.6390, Acc: 85.5072\n",
        "\t\t Training: Epoch(6) - Loss: 0.1792, Acc: 95.9677\n",
        "\t\t Validation(6) - Loss: 0.7840, Acc: 85.5072\n",
        "\t\t Training: Epoch(7) - Loss: 0.1138, Acc: 96.7742\n",
        "\t\t Validation(7) - Loss: 0.4303, Acc: 88.4058\n",
        "\t\t Training: Epoch(8) - Loss: 0.0480, Acc: 98.5484\n",
        "\t\t Validation(8) - Loss: 0.4316, Acc: 88.4058\n",
        "\t\t Training: Epoch(9) - Loss: 0.0622, Acc: 97.9032\n",
        "\t\t Validation(9) - Loss: 0.4203, Acc: 92.7536\n",
        "\t\t Training: Epoch(10) - Loss: 0.0964, Acc: 97.5806\n",
        "\t\t Validation(10) - Loss: 0.7494, Acc: 86.9565\n",
        "\t\t Training: Epoch(11) - Loss: 0.0551, Acc: 98.3871\n",
        "\t\t Validation(11) - Loss: 0.4108, Acc: 88.4058\n",
        "\t\t Training: Epoch(12) - Loss: 0.0736, Acc: 97.2581\n",
        "\t\t Validation(12) - Loss: 0.2768, Acc: 94.2029\n",
        "\t\t Training: Epoch(13) - Loss: 0.0138, Acc: 99.5161\n",
        "\t\t Validation(13) - Loss: 0.3203, Acc: 89.8551\n",
        "\t\t Training: Epoch(14) - Loss: 0.0096, Acc: 99.6774\n",
        "\t\t Validation(14) - Loss: 0.2821, Acc: 91.3043\n",
        "Finished.\n",
        "Total time per fold: 669.8467693328857 seconds.\n",
        "Fold : 1\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.6578, Acc: 55.9677\n",
        "\t\t Validation(0) - Loss: 1.7942, Acc: 47.8261\n",
        "\t\t Training: Epoch(1) - Loss: 0.3869, Acc: 86.9355\n",
        "\t\t Validation(1) - Loss: 0.4094, Acc: 89.8551\n",
        "\t\t Training: Epoch(2) - Loss: 0.3034, Acc: 91.1290\n",
        "\t\t Validation(2) - Loss: 0.4581, Acc: 89.8551\n",
        "\t\t Training: Epoch(3) - Loss: 0.3752, Acc: 89.6774\n",
        "\t\t Validation(3) - Loss: 0.4943, Acc: 85.5072\n",
        "\t\t Training: Epoch(4) - Loss: 0.1716, Acc: 95.3226\n",
        "\t\t Validation(4) - Loss: 0.2245, Acc: 91.3043\n",
        "\t\t Training: Epoch(5) - Loss: 0.1660, Acc: 95.3226\n",
        "\t\t Validation(5) - Loss: 0.7475, Acc: 85.5072\n",
        "\t\t Training: Epoch(6) - Loss: 0.1300, Acc: 96.4516\n",
        "\t\t Validation(6) - Loss: 0.5309, Acc: 89.8551\n",
        "\t\t Training: Epoch(7) - Loss: 0.0744, Acc: 97.5806\n",
        "\t\t Validation(7) - Loss: 0.4378, Acc: 91.3043\n",
        "\t\t Training: Epoch(8) - Loss: 0.0769, Acc: 98.2258\n",
        "\t\t Validation(8) - Loss: 0.3282, Acc: 92.7536\n",
        "\t\t Training: Epoch(9) - Loss: 0.1131, Acc: 96.9355\n",
        "\t\t Validation(9) - Loss: 0.7955, Acc: 85.5072\n",
        "\t\t Training: Epoch(10) - Loss: 0.1871, Acc: 95.9677\n",
        "\t\t Validation(10) - Loss: 0.5083, Acc: 91.3043\n",
        "\t\t Training: Epoch(11) - Loss: 0.0844, Acc: 97.9032\n",
        "\t\t Validation(11) - Loss: 0.5079, Acc: 95.6522\n",
        "\t\t Training: Epoch(12) - Loss: 0.0613, Acc: 97.9032\n",
        "\t\t Validation(12) - Loss: 0.2177, Acc: 91.3043\n",
        "\t\t Training: Epoch(13) - Loss: 0.0154, Acc: 99.5161\n",
        "\t\t Validation(13) - Loss: 0.2138, Acc: 91.3043\n",
        "\t\t Training: Epoch(14) - Loss: 0.0223, Acc: 99.3548\n",
        "\t\t Validation(14) - Loss: 0.4489, Acc: 92.7536\n",
        "Finished.\n",
        "Total time per fold: 656.4339890480042 seconds.\n",
        "Fold : 2\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.6379, Acc: 55.4839\n",
        "\t\t Validation(0) - Loss: 1.4442, Acc: 56.5217\n",
        "\t\t Training: Epoch(1) - Loss: 0.5617, Acc: 83.3871\n",
        "\t\t Validation(1) - Loss: 0.8004, Acc: 82.6087\n",
        "\t\t Training: Epoch(2) - Loss: 0.4036, Acc: 87.0968\n",
        "\t\t Validation(2) - Loss: 0.3178, Acc: 91.3043\n",
        "\t\t Training: Epoch(3) - Loss: 0.2980, Acc: 90.0000\n",
        "\t\t Validation(3) - Loss: 0.2142, Acc: 92.7536\n",
        "\t\t Training: Epoch(4) - Loss: 0.1591, Acc: 95.6452\n",
        "\t\t Validation(4) - Loss: 0.2288, Acc: 91.3043\n",
        "\t\t Training: Epoch(5) - Loss: 0.1016, Acc: 95.9677\n",
        "\t\t Validation(5) - Loss: 0.2956, Acc: 91.3043\n",
        "\t\t Training: Epoch(6) - Loss: 0.1457, Acc: 96.2903\n",
        "\t\t Validation(6) - Loss: 0.1694, Acc: 92.7536\n",
        "\t\t Training: Epoch(7) - Loss: 0.0832, Acc: 97.5806\n",
        "\t\t Validation(7) - Loss: 0.3022, Acc: 95.6522\n",
        "\t\t Training: Epoch(8) - Loss: 0.0993, Acc: 97.4194\n",
        "\t\t Validation(8) - Loss: 0.1473, Acc: 95.6522\n",
        "\t\t Training: Epoch(9) - Loss: 0.1730, Acc: 96.6129\n",
        "\t\t Validation(9) - Loss: 0.5352, Acc: 89.8551\n",
        "\t\t Training: Epoch(10) - Loss: 0.1130, Acc: 96.6129\n",
        "\t\t Validation(10) - Loss: 0.5970, Acc: 89.8551\n",
        "\t\t Training: Epoch(11) - Loss: 0.1226, Acc: 97.4194\n",
        "\t\t Validation(11) - Loss: 0.1235, Acc: 95.6522\n",
        "\t\t Training: Epoch(12) - Loss: 0.0803, Acc: 97.5806\n",
        "\t\t Validation(12) - Loss: 0.2146, Acc: 92.7536\n",
        "\t\t Training: Epoch(13) - Loss: 0.0715, Acc: 98.3871\n",
        "\t\t Validation(13) - Loss: 0.2671, Acc: 95.6522\n",
        "\t\t Training: Epoch(14) - Loss: 0.0935, Acc: 98.0645\n",
        "\t\t Validation(14) - Loss: 0.2244, Acc: 92.7536\n",
        "Finished.\n",
        "Total time per fold: 656.0651466846466 seconds.\n",
        "Fold : 3\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.5997, Acc: 57.0968\n",
        "\t\t Validation(0) - Loss: 1.7421, Acc: 53.6232\n",
        "\t\t Training: Epoch(1) - Loss: 0.4651, Acc: 85.1613\n",
        "\t\t Validation(1) - Loss: 0.5389, Acc: 85.5072\n",
        "\t\t Training: Epoch(2) - Loss: 0.2826, Acc: 92.0968\n",
        "\t\t Validation(2) - Loss: 0.3839, Acc: 89.8551\n",
        "\t\t Training: Epoch(3) - Loss: 0.2425, Acc: 91.9355\n",
        "\t\t Validation(3) - Loss: 0.2250, Acc: 92.7536\n",
        "\t\t Training: Epoch(4) - Loss: 0.2013, Acc: 94.8387\n",
        "\t\t Validation(4) - Loss: 0.3153, Acc: 88.4058\n",
        "\t\t Training: Epoch(5) - Loss: 0.1751, Acc: 93.7097\n",
        "\t\t Validation(5) - Loss: 0.4091, Acc: 86.9565\n",
        "\t\t Training: Epoch(6) - Loss: 0.0958, Acc: 96.9355\n",
        "\t\t Validation(6) - Loss: 0.3122, Acc: 91.3043\n",
        "\t\t Training: Epoch(7) - Loss: 0.1601, Acc: 95.1613\n",
        "\t\t Validation(7) - Loss: 0.2990, Acc: 92.7536\n",
        "\t\t Training: Epoch(8) - Loss: 0.0717, Acc: 97.4194\n",
        "\t\t Validation(8) - Loss: 0.3687, Acc: 92.7536\n",
        "\t\t Training: Epoch(9) - Loss: 0.0972, Acc: 97.9032\n",
        "\t\t Validation(9) - Loss: 0.1897, Acc: 94.2029\n",
        "\t\t Training: Epoch(10) - Loss: 0.0127, Acc: 99.6774\n",
        "\t\t Validation(10) - Loss: 0.1812, Acc: 94.2029\n",
        "\t\t Training: Epoch(11) - Loss: 0.0359, Acc: 99.0323\n",
        "\t\t Validation(11) - Loss: 0.2605, Acc: 91.3043\n",
        "\t\t Training: Epoch(12) - Loss: 0.0118, Acc: 99.5161\n",
        "\t\t Validation(12) - Loss: 0.3594, Acc: 91.3043\n",
        "\t\t Training: Epoch(13) - Loss: 0.0455, Acc: 98.8710\n",
        "\t\t Validation(13) - Loss: 0.1670, Acc: 94.2029\n",
        "\t\t Training: Epoch(14) - Loss: 0.0286, Acc: 98.8710\n",
        "\t\t Validation(14) - Loss: 0.5240, Acc: 92.7536\n",
        "Finished.\n",
        "Total time per fold: 646.6555397510529 seconds.\n",
        "Fold : 4\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.7609, Acc: 55.0000\n",
        "\t\t Validation(0) - Loss: 1.2189, Acc: 63.7681\n",
        "\t\t Training: Epoch(1) - Loss: 0.5894, Acc: 83.2258\n",
        "\t\t Validation(1) - Loss: 0.3059, Acc: 92.7536\n",
        "\t\t Training: Epoch(2) - Loss: 0.4547, Acc: 86.9355\n",
        "\t\t Validation(2) - Loss: 0.4786, Acc: 84.0580\n",
        "\t\t Training: Epoch(3) - Loss: 0.2852, Acc: 90.0000\n",
        "\t\t Validation(3) - Loss: 0.2872, Acc: 88.4058\n",
        "\t\t Training: Epoch(4) - Loss: 0.1536, Acc: 95.1613\n",
        "\t\t Validation(4) - Loss: 0.2094, Acc: 91.3043\n",
        "\t\t Training: Epoch(5) - Loss: 0.1197, Acc: 96.2903\n",
        "\t\t Validation(5) - Loss: 0.1281, Acc: 94.2029\n",
        "\t\t Training: Epoch(6) - Loss: 0.1094, Acc: 97.2581\n",
        "\t\t Validation(6) - Loss: 0.3312, Acc: 92.7536\n",
        "\t\t Training: Epoch(7) - Loss: 0.0513, Acc: 98.5484\n",
        "\t\t Validation(7) - Loss: 0.4139, Acc: 89.8551\n",
        "\t\t Training: Epoch(8) - Loss: 0.1145, Acc: 96.7742\n",
        "\t\t Validation(8) - Loss: 0.1838, Acc: 94.2029\n",
        "\t\t Training: Epoch(9) - Loss: 0.0454, Acc: 98.2258\n",
        "\t\t Validation(9) - Loss: 0.2753, Acc: 91.3043\n",
        "\t\t Training: Epoch(10) - Loss: 0.0561, Acc: 97.7419\n",
        "\t\t Validation(10) - Loss: 0.3317, Acc: 89.8551\n",
        "\t\t Training: Epoch(11) - Loss: 0.1005, Acc: 97.4194\n",
        "\t\t Validation(11) - Loss: 0.3123, Acc: 89.8551\n",
        "\t\t Training: Epoch(12) - Loss: 0.0334, Acc: 98.5484\n",
        "\t\t Validation(12) - Loss: 0.2477, Acc: 91.3043\n",
        "\t\t Training: Epoch(13) - Loss: 0.0574, Acc: 98.3871\n",
        "\t\t Validation(13) - Loss: 0.1434, Acc: 92.7536\n",
        "\t\t Training: Epoch(14) - Loss: 0.0538, Acc: 99.0323\n",
        "\t\t Validation(14) - Loss: 0.2347, Acc: 91.3043\n",
        "Finished.\n",
        "Total time per fold: 649.2717716693878 seconds.\n",
        "Fold : 5\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.7177, Acc: 55.4839\n",
        "\t\t Validation(0) - Loss: 2.0823, Acc: 47.8261\n",
        "\t\t Training: Epoch(1) - Loss: 0.5853, Acc: 80.9677\n",
        "\t\t Validation(1) - Loss: 0.5014, Acc: 86.9565\n",
        "\t\t Training: Epoch(2) - Loss: 0.3458, Acc: 89.3548\n",
        "\t\t Validation(2) - Loss: 0.4835, Acc: 85.5072\n",
        "\t\t Training: Epoch(3) - Loss: 0.2926, Acc: 91.2903\n",
        "\t\t Validation(3) - Loss: 0.5963, Acc: 86.9565\n",
        "\t\t Training: Epoch(4) - Loss: 0.1988, Acc: 94.3548\n",
        "\t\t Validation(4) - Loss: 0.4931, Acc: 89.8551\n",
        "\t\t Training: Epoch(5) - Loss: 0.1263, Acc: 96.1290\n",
        "\t\t Validation(5) - Loss: 0.2822, Acc: 92.7536\n",
        "\t\t Training: Epoch(6) - Loss: 0.1513, Acc: 95.8065\n",
        "\t\t Validation(6) - Loss: 0.5524, Acc: 86.9565\n",
        "\t\t Training: Epoch(7) - Loss: 0.1180, Acc: 96.7742\n",
        "\t\t Validation(7) - Loss: 0.2433, Acc: 91.3043\n",
        "\t\t Training: Epoch(8) - Loss: 0.0945, Acc: 97.4194\n",
        "\t\t Validation(8) - Loss: 0.2529, Acc: 94.2029\n",
        "\t\t Training: Epoch(9) - Loss: 0.1632, Acc: 96.4516\n",
        "\t\t Validation(9) - Loss: 0.4000, Acc: 84.0580\n",
        "\t\t Training: Epoch(10) - Loss: 0.0628, Acc: 98.3871\n",
        "\t\t Validation(10) - Loss: 0.2364, Acc: 92.7536\n",
        "\t\t Training: Epoch(11) - Loss: 0.0682, Acc: 98.7097\n",
        "\t\t Validation(11) - Loss: 0.2897, Acc: 89.8551\n",
        "\t\t Training: Epoch(12) - Loss: 0.0376, Acc: 99.3548\n",
        "\t\t Validation(12) - Loss: 0.1112, Acc: 95.6522\n",
        "\t\t Training: Epoch(13) - Loss: 0.0198, Acc: 99.5161\n",
        "\t\t Validation(13) - Loss: 0.1047, Acc: 95.6522\n",
        "\t\t Training: Epoch(14) - Loss: 0.0580, Acc: 99.0323\n",
        "\t\t Validation(14) - Loss: 0.0700, Acc: 98.5507\n",
        "Finished.\n",
        "Total time per fold: 656.2941517829895 seconds.\n",
        "Fold : 6\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.6610, Acc: 55.4839\n",
        "\t\t Validation(0) - Loss: 1.5797, Acc: 56.5217\n",
        "\t\t Training: Epoch(1) - Loss: 0.4162, Acc: 86.6129\n",
        "\t\t Validation(1) - Loss: 0.4281, Acc: 86.9565\n",
        "\t\t Training: Epoch(2) - Loss: 0.3656, Acc: 88.2258\n",
        "\t\t Validation(2) - Loss: 0.4516, Acc: 89.8551\n",
        "\t\t Training: Epoch(3) - Loss: 0.2919, Acc: 91.1290\n",
        "\t\t Validation(3) - Loss: 0.3251, Acc: 91.3043\n",
        "\t\t Training: Epoch(4) - Loss: 0.2362, Acc: 94.1935\n",
        "\t\t Validation(4) - Loss: 0.5021, Acc: 88.4058\n",
        "\t\t Training: Epoch(5) - Loss: 0.0937, Acc: 97.2581\n",
        "\t\t Validation(5) - Loss: 0.3423, Acc: 89.8551\n",
        "\t\t Training: Epoch(6) - Loss: 0.1173, Acc: 97.4194\n",
        "\t\t Validation(6) - Loss: 0.3652, Acc: 89.8551\n",
        "\t\t Training: Epoch(7) - Loss: 0.1183, Acc: 96.1290\n",
        "\t\t Validation(7) - Loss: 0.2434, Acc: 92.7536\n",
        "\t\t Training: Epoch(8) - Loss: 0.1273, Acc: 96.7742\n",
        "\t\t Validation(8) - Loss: 0.3416, Acc: 89.8551\n",
        "\t\t Training: Epoch(9) - Loss: 0.1570, Acc: 95.6452\n",
        "\t\t Validation(9) - Loss: 0.2990, Acc: 92.7536\n",
        "\t\t Training: Epoch(10) - Loss: 0.1088, Acc: 97.5806\n",
        "\t\t Validation(10) - Loss: 0.5526, Acc: 86.9565\n",
        "\t\t Training: Epoch(11) - Loss: 0.0804, Acc: 97.2581\n",
        "\t\t Validation(11) - Loss: 0.4313, Acc: 88.4058\n",
        "\t\t Training: Epoch(12) - Loss: 0.0400, Acc: 99.0323\n",
        "\t\t Validation(12) - Loss: 0.4225, Acc: 89.8551\n",
        "\t\t Training: Epoch(13) - Loss: 0.0464, Acc: 98.2258\n",
        "\t\t Validation(13) - Loss: 0.3482, Acc: 94.2029\n",
        "\t\t Training: Epoch(14) - Loss: 0.0464, Acc: 98.2258\n",
        "\t\t Validation(14) - Loss: 0.3336, Acc: 92.7536\n",
        "Finished.\n",
        "Total time per fold: 655.8265824317932 seconds.\n",
        "Fold : 7\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.6276, Acc: 57.4194\n",
        "\t\t Validation(0) - Loss: 1.1767, Acc: 63.7681\n",
        "\t\t Training: Epoch(1) - Loss: 0.4749, Acc: 84.6774\n",
        "\t\t Validation(1) - Loss: 0.5479, Acc: 81.1594\n",
        "\t\t Training: Epoch(2) - Loss: 0.4465, Acc: 86.7742\n",
        "\t\t Validation(2) - Loss: 0.3537, Acc: 88.4058\n",
        "\t\t Training: Epoch(3) - Loss: 0.3416, Acc: 90.8065\n",
        "\t\t Validation(3) - Loss: 0.5831, Acc: 86.9565\n",
        "\t\t Training: Epoch(4) - Loss: 0.2634, Acc: 92.9032\n",
        "\t\t Validation(4) - Loss: 0.3241, Acc: 89.8551\n",
        "\t\t Training: Epoch(5) - Loss: 0.1770, Acc: 95.9677\n",
        "\t\t Validation(5) - Loss: 0.1593, Acc: 97.1014\n",
        "\t\t Training: Epoch(6) - Loss: 0.0888, Acc: 97.5806\n",
        "\t\t Validation(6) - Loss: 0.4496, Acc: 92.7536\n",
        "\t\t Training: Epoch(7) - Loss: 0.0597, Acc: 97.9032\n",
        "\t\t Validation(7) - Loss: 0.2113, Acc: 94.2029\n",
        "\t\t Training: Epoch(8) - Loss: 0.0846, Acc: 97.9032\n",
        "\t\t Validation(8) - Loss: 0.3210, Acc: 92.7536\n",
        "\t\t Training: Epoch(9) - Loss: 0.0699, Acc: 98.2258\n",
        "\t\t Validation(9) - Loss: 0.2608, Acc: 95.6522\n",
        "\t\t Training: Epoch(10) - Loss: 0.2384, Acc: 96.6129\n",
        "\t\t Validation(10) - Loss: 0.5815, Acc: 88.4058\n",
        "\t\t Training: Epoch(11) - Loss: 0.1032, Acc: 97.0968\n",
        "\t\t Validation(11) - Loss: 0.2060, Acc: 97.1014\n",
        "\t\t Training: Epoch(12) - Loss: 0.0616, Acc: 98.3871\n",
        "\t\t Validation(12) - Loss: 0.1328, Acc: 97.1014\n",
        "\t\t Training: Epoch(13) - Loss: 0.0409, Acc: 98.7097\n",
        "\t\t Validation(13) - Loss: 0.0995, Acc: 95.6522\n",
        "\t\t Training: Epoch(14) - Loss: 0.1104, Acc: 97.7419\n",
        "\t\t Validation(14) - Loss: 0.2306, Acc: 95.6522\n",
        "Finished.\n",
        "Total time per fold: 649.9659056663513 seconds.\n",
        "Fold : 8\n",
        "Samples in training: 620\n",
        "Samples in test: 69\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.5873, Acc: 57.9032\n",
        "\t\t Validation(0) - Loss: 1.9093, Acc: 52.1739\n",
        "\t\t Training: Epoch(1) - Loss: 0.4703, Acc: 83.3871\n",
        "\t\t Validation(1) - Loss: 0.5094, Acc: 86.9565\n",
        "\t\t Training: Epoch(2) - Loss: 0.2275, Acc: 92.5806\n",
        "\t\t Validation(2) - Loss: 0.2865, Acc: 91.3043\n",
        "\t\t Training: Epoch(3) - Loss: 0.2198, Acc: 93.5484\n",
        "\t\t Validation(3) - Loss: 0.1822, Acc: 94.2029\n",
        "\t\t Training: Epoch(4) - Loss: 0.2174, Acc: 93.5484\n",
        "\t\t Validation(4) - Loss: 0.6397, Acc: 89.8551\n",
        "\t\t Training: Epoch(5) - Loss: 0.1751, Acc: 95.1613\n",
        "\t\t Validation(5) - Loss: 0.2521, Acc: 94.2029\n",
        "\t\t Training: Epoch(6) - Loss: 0.1970, Acc: 94.3548\n",
        "\t\t Validation(6) - Loss: 0.5809, Acc: 89.8551\n",
        "\t\t Training: Epoch(7) - Loss: 0.2503, Acc: 93.8710\n",
        "\t\t Validation(7) - Loss: 0.4294, Acc: 88.4058\n",
        "\t\t Training: Epoch(8) - Loss: 0.1182, Acc: 96.2903\n",
        "\t\t Validation(8) - Loss: 0.3031, Acc: 91.3043\n",
        "\t\t Training: Epoch(9) - Loss: 0.0937, Acc: 97.7419\n",
        "\t\t Validation(9) - Loss: 0.3464, Acc: 94.2029\n",
        "\t\t Training: Epoch(10) - Loss: 0.0338, Acc: 99.1935\n",
        "\t\t Validation(10) - Loss: 0.3562, Acc: 92.7536\n",
        "\t\t Training: Epoch(11) - Loss: 0.0394, Acc: 99.1935\n",
        "\t\t Validation(11) - Loss: 0.3197, Acc: 95.6522\n",
        "\t\t Training: Epoch(12) - Loss: 0.0098, Acc: 99.6774\n",
        "\t\t Validation(12) - Loss: 0.2450, Acc: 94.2029\n",
        "\t\t Training: Epoch(13) - Loss: 0.0732, Acc: 98.2258\n",
        "\t\t Validation(13) - Loss: 0.5229, Acc: 88.4058\n",
        "\t\t Training: Epoch(14) - Loss: 0.1150, Acc: 96.7742\n",
        "\t\t Validation(14) - Loss: 0.2533, Acc: 92.7536\n",
        "Finished.\n",
        "Total time per fold: 653.4133305549622 seconds.\n",
        "Fold : 9\n",
        "Samples in training: 621\n",
        "Samples in test: 68\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "/usr/local/lib/python3.10/dist-packages/xformers/components/attention/base.py:40: FutureWarning: ScaledDotProduct() is deprecated and is not maintained anymore. It might be removed in a future version of xFormers\n",
        "  deprecated_function(self)\n",
        "-----------------------------------------------------------------------------\n",
        "          Layer (type)          Output Shape         Param #     Tr. Param #\n",
        "=============================================================================\n",
        "    TransformerBlock-1     [1, 32, 112, 112]          13,754          13,754\n",
        "    TransformerBlock-2     [1, 16, 112, 112]           4,036           4,036\n",
        "    TransformerBlock-3       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-4       [1, 24, 56, 56]           8,142           8,142\n",
        "    TransformerBlock-5       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-6       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-7       [1, 32, 28, 28]          13,754          13,754\n",
        "    TransformerBlock-8       [1, 64, 14, 14]          49,972          49,972\n",
        "    TransformerBlock-9       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-10       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-11       [1, 64, 14, 14]          49,972          49,972\n",
        "   TransformerBlock-12       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-13       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-14       [1, 96, 14, 14]         108,654         108,654\n",
        "   TransformerBlock-15        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-16        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-17        [1, 160, 7, 7]         293,410         293,410\n",
        "   TransformerBlock-18        [1, 320, 7, 7]       1,149,398       1,149,398\n",
        "   TransformerBlock-19       [1, 1280, 7, 7]      18,087,512      18,087,512\n",
        "             Linear-20               [1, 32]          40,992          40,992\n",
        "=============================================================================\n",
        "Total params: 20,759,318\n",
        "Trainable params: 20,759,318\n",
        "Non-trainable params: 0\n",
        "-----------------------------------------------------------------------------\n",
        "\t\t Training: Epoch(0) - Loss: 1.7345, Acc: 52.3349\n",
        "\t\t Validation(0) - Loss: 1.3374, Acc: 60.2941\n",
        "\t\t Training: Epoch(1) - Loss: 0.5159, Acc: 82.7697\n",
        "\t\t Validation(1) - Loss: 0.2270, Acc: 91.1765\n",
        "\t\t Training: Epoch(2) - Loss: 0.3618, Acc: 87.9227\n",
        "\t\t Validation(2) - Loss: 0.2060, Acc: 91.1765\n",
        "\t\t Training: Epoch(3) - Loss: 0.2802, Acc: 91.1433\n",
        "\t\t Validation(3) - Loss: 0.2835, Acc: 94.1176\n",
        "\t\t Training: Epoch(4) - Loss: 0.1626, Acc: 95.3301\n",
        "\t\t Validation(4) - Loss: 0.4039, Acc: 88.2353\n",
        "\t\t Training: Epoch(5) - Loss: 0.0902, Acc: 96.9404\n",
        "\t\t Validation(5) - Loss: 0.3060, Acc: 92.6471\n",
        "\t\t Training: Epoch(6) - Loss: 0.0513, Acc: 97.9066\n",
        "\t\t Validation(6) - Loss: 0.2663, Acc: 92.6471\n",
        "\t\t Training: Epoch(7) - Loss: 0.1204, Acc: 97.2625\n",
        "\t\t Validation(7) - Loss: 0.2030, Acc: 91.1765\n",
        "\t\t Training: Epoch(8) - Loss: 0.0790, Acc: 97.7456\n",
        "\t\t Validation(8) - Loss: 0.2198, Acc: 88.2353\n",
        "\t\t Training: Epoch(9) - Loss: 0.1234, Acc: 96.9404\n",
        "\t\t Validation(9) - Loss: 0.2579, Acc: 89.7059\n",
        "\t\t Training: Epoch(10) - Loss: 0.0595, Acc: 97.4235\n",
        "\t\t Validation(10) - Loss: 0.3244, Acc: 89.7059\n",
        "\t\t Training: Epoch(11) - Loss: 0.0823, Acc: 98.3897\n",
        "\t\t Validation(11) - Loss: 0.2094, Acc: 95.5882\n",
        "\t\t Training: Epoch(12) - Loss: 0.0308, Acc: 98.7118\n",
        "\t\t Validation(12) - Loss: 0.0768, Acc: 95.5882\n",
        "\t\t Training: Epoch(13) - Loss: 0.0391, Acc: 98.7118\n",
        "\t\t Validation(13) - Loss: 0.1223, Acc: 97.0588\n",
        "\t\t Training: Epoch(14) - Loss: 0.0403, Acc: 98.7118\n",
        "\t\t Validation(14) - Loss: 0.2438, Acc: 91.1765\n",
        "Finished.\n",
        "Total time per fold: 654.7385499477386 seconds.\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
